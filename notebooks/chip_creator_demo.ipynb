{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# InstaGeo Chip Creator Demo\n",
        "\n",
        "This notebook demonstrates how to use the `chip_creator.py` module to create satellite image chips and segmentation maps from point observations. The chip creator is designed to extract small image patches (chips) from larger satellite tiles based on point observations, making it suitable for training machine learning models.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The chip creator module:\n",
        "- Extracts satellite imagery (HLS, Sentinel-1, Sentinel-2)\n",
        "- Creates chips around observation points\n",
        "- Generates segmentation maps for training\n",
        "- Supports multiple data sources and processing methods\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before running this notebook, ensure you have:\n",
        "1. InstaGeo installed\n",
        "2. NASA Earthdata credentials configured\n",
        "3. A CSV file with observation data containing columns: date, x, y, label (will be created with the `create_sample_data` function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up paths\n",
        "notebook_dir = Path.cwd()\n",
        "data_dir = notebook_dir / \"demo_data\"\n",
        "output_dir = notebook_dir / \"chip_output\"\n",
        "\n",
        "# Create directories\n",
        "data_dir.mkdir(exist_ok=True)\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Data directory: {data_dir}\")\n",
        "print(f\"Output directory: {output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Sample Observation Data\n",
        "\n",
        "Let's create a sample dataset to demonstrate the chip creator functionality. In practice, this would represent your original point observations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample observation data\n",
        "np.random.seed(42)\n",
        "n_samples = 50\n",
        "\n",
        "# Sample coordinates around Paris area\n",
        "lat_center, lon_center = 48.8566, 2.3522\n",
        "lat_range, lon_range = 0.5, 0.5\n",
        "\n",
        "sample_data = {\n",
        "    'date': pd.date_range('2023-06-14', periods=n_samples, freq='D').strftime('%Y-%m-%d'),\n",
        "    'x': np.random.uniform(lon_center - lon_range, lon_center + lon_range, n_samples),\n",
        "    'y': np.random.uniform(lat_center - lat_range, lat_center + lat_range, n_samples),\n",
        "    'label': np.random.choice(['crop', 'forest', 'urban', 'water'], n_samples, p=[0.4, 0.3, 0.2, 0.1])\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(sample_data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert string labels to integers (required for chip creator)\n",
        "label_mapping = {'crop': 1, 'forest': 2, 'urban': 3, 'water': 4}\n",
        "df['label_int'] = df['label'].map(label_mapping)\n",
        "\n",
        "print(\"Label mapping:\")\n",
        "for label, label_int in label_mapping.items():\n",
        "    print(f\"  {label}: {label_int}\")\n",
        "\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "print(f\"\\nInteger label distribution:\")\n",
        "print(df['label_int'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save sample data with integer labels\n",
        "sample_file = data_dir / \"sample_observations.csv\"\n",
        "df_final = df[['date', 'x', 'y', 'label_int']].copy()\n",
        "df_final.columns = ['date', 'x', 'y', 'label']  # Rename label_int back to label\n",
        "df_final.to_csv(sample_file, index=False)\n",
        "\n",
        "print(f\"Sample data saved to: {sample_file}\")\n",
        "print(f\"Dataset shape: {df_final.shape}\")\n",
        "print(f\"Date range: {df_final['date'].min()} to {df_final['date'].max()}\")\n",
        "print(f\"Label range: {df_final['label'].min()} to {df_final['label'].max()}\")\n",
        "print(f\"\\nFinal dataset preview:\")\n",
        "print(df_final.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Visualizing Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the sample data\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Spatial distribution\n",
        "colors = {1: 'green', 2: 'darkgreen', 3: 'red', 4: 'blue'}\n",
        "label_names = {1: 'crop', 2: 'forest', 3: 'urban', 4: 'water'}\n",
        "\n",
        "for label_int in df_final['label'].unique():\n",
        "    mask = df_final['label'] == label_int\n",
        "    ax1.scatter(df_final[mask]['x'], df_final[mask]['y'], \n",
        "               c=colors[label_int], label=label_names[label_int], alpha=0.7, s=50)\n",
        "\n",
        "ax1.set_xlabel('Longitude')\n",
        "ax1.set_ylabel('Latitude')\n",
        "ax1.set_title('Spatial Distribution of Observations')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Temporal distribution\n",
        "df_final['date_parsed'] = pd.to_datetime(df_final['date'])\n",
        "df_final['month'] = df_final['date_parsed'].dt.month\n",
        "monthly_counts = df_final.groupby(['month', 'label']).size().unstack(fill_value=0)\n",
        "monthly_counts.plot(kind='bar', ax=ax2, color=[colors[label] for label in monthly_counts.columns])\n",
        "ax2.set_xlabel('Month')\n",
        "ax2.set_ylabel('Number of Observations')\n",
        "ax2.set_title('Temporal Distribution by Month')\n",
        "ax2.legend(title='Label', labels=[label_names[label] for label in monthly_counts.columns])\n",
        "ax2.tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Usage Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 1: Basic usage with HLS data\n",
        "We want to create chips of size 256x256 using one timestep with a temporal tolerance of 2 days, with their corresponding segmentation maps.\n",
        "This means for each record, we will use the closest available image to the observation date retrieved using a time window starting 2 days before and ending 2 days after the observation date. The label values from the original observations will be used to set pixel values in the segmentation maps. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m instageo.data.chip_creator \\\n",
        "    --dataframe_path=\"demo_data/sample_observations.csv\" \\\n",
        "    --output_directory=\"chip_output/hls_basic\" \\\n",
        "    --min_count=1 \\\n",
        "    --temporal_tolerance=2 \\\n",
        "    --chip_size=256 \\\n",
        "    --num_steps=1 \\\n",
        "    --data_source=\"HLS\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Multiple temporal chips with HLS data.\n",
        "\n",
        "This example creates a multitemporal dataset with 3-timesteps chips and their corresponding segmentation maps . This could be useful if we are working on a task related to tracking changes over an area for a given period or if we are interested in capturing variations that could improve the results of a classification task at a given date. The `temporal_step` argument is the number of days we want to have between each step. The `num_steps` argument is the total number of steps. Here we want to create 3-timesteps chips with monthly increment in recording times from the original observation date.\n",
        "Given that we might not find an image for each timestep at the exact date, we can set the `temporal_tolerance` argument to a higher value to allow for more flexibility in the date search. It is important to note that a very high value could break the intended seasonality of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m instageo.data.chip_creator \\\n",
        "    --dataframe_path=\"demo_data/sample_observations.csv\" \\\n",
        "    --output_directory=\"chip_output/hls_multitemporal\" \\\n",
        "    --min_count=1 \\\n",
        "    --chip_size=256 \\\n",
        "    --temporal_tolerance=3 \\\n",
        "    --temporal_step=30 \\\n",
        "    --num_steps=3 \\\n",
        "    --data_source=\"HLS\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 3: HLS chips with cloud coverage filtering and masking\n",
        "This example creates a dataset with chips and segmentation maps, but only includes records with cloud coverage less than 20%.\n",
        "Note that the cloud percentage is verified at the HLS tile level, not at the chip level.\n",
        "This means that if a tile has a cloud coverage of 20%+, all records/chips that could be potentially extracted from that tile will be discarded.\n",
        "We also mask clouds (using `mask_types` set to cloud and cloud_shadow) by setting corresponding pixels to `no_data` values (both in the chips and the segmentation maps, respectively 0 and -1; check `data/settings.py`). We use the `masking_strategy` argument to specify how to apply the masking. Here we use the `any` strategy, which means that if the mask is present for at least one timestep, the pixel will be masked.\n",
        "\n",
        "To address the issue of potentially discarded chips, we can set the `cloud_coverage` argument to a higher value to allow for more flexibility in the search and consider more tiles and still apply masking. We could then filter chips by setting a threshold on `no_data` values percentage (this is not covered in this notebook. See the `data_cleaner_demo.ipynb` or `data/data_cleaner.py` module for more details).\n",
        "\n",
        "Note that by default, if you don't set the `cloud_coverage` argument a value of 10 is used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m instageo.data.chip_creator \\\n",
        "    --dataframe_path=\"demo_data/sample_observations.csv\" \\\n",
        "    --output_directory=\"chip_output/hls_cloud_filtered\" \\\n",
        "    --min_count=1 \\\n",
        "    --chip_size=256 \\\n",
        "    --temporal_tolerance=2 \\\n",
        "    --num_steps=1 \\\n",
        "    --cloud_coverage=20 \\\n",
        "    --mask_types=\"cloud,cloud_shadow\" \\\n",
        "    --masking_strategy=\"any\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 4: Buffered observation points\n",
        "In many applications, when generating the chips and segmentation maps datasets we might be interested in uniformizing the neighborhood of the observation points to include more pixels. To do this we set the same value for neighboring pixels as the pixel in which the observation falls. This can be done by setting the `window_size` argument to a value greater than 0. Using the basic HLS example, we can set the `window_size` argument to 2, this will include 2 pixels in all directions around the observation pixel.\n",
        "\n",
        "Note that the default value for `window_size` is 0, meaning no buffer will be applied. \n",
        "To account for variable window sizes we can keep a value of 0 and then generate different variants for the segmentation maps using the `data/data_cleaner.py` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m instageo.data.chip_creator \\\n",
        "    --dataframe_path=\"demo_data/sample_observations.csv\" \\\n",
        "    --output_directory=\"chip_output/hls_buffered\" \\\n",
        "    --min_count=1 \\\n",
        "    --chip_size=256\\\n",
        "    --temporal_tolerance=2 \\\n",
        "    --num_steps=1 \\\n",
        "    --data_source=\"HLS\" \\\n",
        "    --window_size=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 5: Sentinel-2 example\n",
        "For Sentinel-2 and Sentinel-1, we set the spatial resolution to 10m in EPSG:4326. The default value corresponds to 30m in EPSG:4326 (for HLS data).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m instageo.data.chip_creator \\\n",
        "    --dataframe_path=\"demo_data/sample_observations.csv\" \\\n",
        "    --output_directory=\"chip_output/s2_example\" \\\n",
        "    --min_count=1 \\\n",
        "    --chip_size=256 \\\n",
        "    --temporal_tolerance=5 \\\n",
        "    --num_steps=1 \\\n",
        "    --data_source=\"S2\" \\\n",
        "    --cloud_coverage=20 \\\n",
        "    --spatial_resolution=8.983152841195215e-05 #10m resolution in EPSG:4326"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 6: Sentinel-1 example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m instageo.data.chip_creator \\\n",
        "    --dataframe_path=\"demo_data/sample_observations.csv\" \\\n",
        "    --output_directory=\"chip_output/s1_example\" \\\n",
        "    --min_count=1 \\\n",
        "    --chip_size=256 \\\n",
        "    --temporal_tolerance=5 \\\n",
        "    --num_steps=1 \\\n",
        "    --data_source=\"S1\" \\\n",
        "    --spatial_resolution=8.983152841195215e-05 #10m resolution in EPSG:4326"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 7: Regression example\n",
        "All the past examples have been focused on segmentation tasks. \n",
        "If the label was a continuous variable (let's say if the label is not representing indices to class names but rather a \"count variable\" for instance), we could use the `task_type` argument set to `reg` to create a regression dataset.\n",
        "In that case, the segmentation maps data type will be set to `float32` \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m instageo.data.chip_creator \\\n",
        "    --dataframe_path=\"demo_data/sample_observations.csv\" \\\n",
        "    --output_directory=\"chip_output/hls_regression\" \\\n",
        "    --min_count=1 \\\n",
        "    --chip_size=256 \\\n",
        "    --temporal_tolerance=2 \\\n",
        "    --num_steps=1 \\\n",
        "    --data_source=\"HLS\"\\\n",
        "    --task_type=\"reg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Troubleshooting Common Issues\n",
        "\n",
        "Here are solutions to common problems:\n",
        "\n",
        "| Issue | Problem | Solution | Command/Args |\n",
        "|-------|---------|----------|--------------|\n",
        "| Authentication Error | NASA Earthdata login failed | Configure ~/.netrc with Earthdata credentials | `echo 'machine urs.earthdata.nasa.gov login <username> password <password>' >> ~/.netrc` |\n",
        "| No Data Found | No observations found/ No objects to concatenate | Increase temporal_tolerance, or cloud_coverage (not applicable for Sentinel-1), or check date ranges of your observations | `--temporal_tolerance=10 --cloud_coverage=50` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Next Steps\n",
        "\n",
        "After creating chips, you can:\n",
        "\n",
        "1. **Clean the data** using `data_cleaner.py`\n",
        "2. **Split the dataset** using `data_splitter.py`\n",
        "3. **Train machine learning models and Evaluate model performance** (Take a look at training scripts in `experiments_dir`)\n",
        "4. Or you can generate optionally chips with `raster_chip_creator.py`\n",
        "\n",
        "See the other demo notebooks for these next steps!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary\n",
        "\n",
        "The chip creator is a powerful tool for creating patches/chips data from satellite imagery. Key takeaways:\n",
        "\n",
        "- **Flexible data sources**: Supports HLS, Sentinel-1, Sentinel-2\n",
        "- **Time series support**: Create temporal sequences for time series models\n",
        "- **Quality assurance**: Built-in validation and filtering\n",
        "- **Scalable**: Can process large datasets efficiently\n",
        "\n",
        "For more information, see the InstaGeo documentation and other demo notebooks.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
